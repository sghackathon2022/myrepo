{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sghackathon2022/myrepo/blob/main/ESG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTOO3kmUnYgs",
        "outputId": "8df5f6fd-49f7-4021-91a2-267b015241be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPS2UptAoHNB",
        "outputId": "b3b0b79c-0fa8-449e-f8fd-8c8e2a37f4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 77.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install torchvision \n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.tagged import NLTKWordTokenizer\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/dataset1.csv')\n",
        "def clean_text(message):\n",
        "  message=message.lower()\n",
        "  message=re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',message,flags=re.MULTILINE)\n",
        "  reg_pattern=re.compile(pattern=\"[\"\n",
        "                                   u\"\\U0001F600-\\U0001F64F\"\n",
        "                                   u\"\\U0001F300-\\U0001F5FF\"\n",
        "                                   u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                                   u\"\\U000026A1\"\n",
        "                                   \"]+\",flags=re.UNICODE)\n",
        "  message=reg_pattern.sub(r'',message)\n",
        "\n",
        "  words=word_tokenize(message)\n",
        "  stop_words=stopwords.words('english')\n",
        "  words=[i for i in words if i.strip() !=\"\" and i not in stop_words and i not in string.punctuation]\n",
        "  #ps=nltk.PorterStemmer()\n",
        "  wn=nltk.WordNetLemmatizer()\n",
        "  return \" \".join([wn.lemmatize(word) for word in words])\n",
        "def remove_extraspace(message):\n",
        "  message=message.lower()\n",
        "  message=re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',message,flags=re.MULTILINE)\n",
        "  reg_pattern=re.compile(pattern=\"[\"\n",
        "                                   u\"\\U0001F600-\\U0001F64F\"\n",
        "                                   u\"\\U0001F300-\\U0001F5FF\"\n",
        "                                   u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                                   u\"\\U000026A1\"\n",
        "                                   \"]+\",flags=re.UNICODE)\n",
        "  message=reg_pattern.sub(r'',message)\n",
        "\n",
        "  words=word_tokenize(message)\n",
        "  return \" \".join([i for i in words if i.strip() !=\"\" ])\n",
        "\n",
        "rm_space=[]\n",
        "cln_data=[]\n",
        "for ind in df['News'].index:\n",
        "  cln_data.append(clean_text(str(df['Title'][ind])+\"\\n\"+str(df['News'][ind])))\n",
        "  rm_space.append(remove_extraspace(str(df['Title'][ind])+\"\\n\"+str(df['News'][ind])))\n",
        "df['clean_data']=cln_data\n",
        "df['data']=rm_space\n",
        "df.columns\n",
        "message=df['Title'][27]+\"\\n\"+df[\"News\"][27]\n",
        "clean_msg=df['clean_data'][27]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNcF7sBG4Wr6",
        "outputId": "2c359d02-eff2-4f0a-8c5b-9822995a565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1=\"there were allegations of sexual assault against reliance \"\n",
        "data2=\"I hate you\"\n",
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer,pipeline\n",
        "sent_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\", num_labels=3)\n",
        "sent_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "sent_nlp=pipeline(\"text-classification\",model=sent_model,tokenizer=sent_tokenizer)\n",
        "dict1={\"LABEL_0\":\"NEUTRAL\",\"LABEL_1\":\"POSITIVE\",\"LABEL_2\":\"NEGATIVE\"}\n",
        "#data=dict1[sent_nlp(df['clean_data'][0])[0][\"label\"]]\n",
        "#data2=dict1[sent_nlp(\"I hate you\")[0][\"label\"]]\n",
        "print(sent_nlp(df['clean_data'][0])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVvfrkRjyiHQ",
        "outputId": "2bd561ce-8def-4d59-ac33-c75c985244dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'Neutral', 'score': 0.998387336730957}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification,AutoTokenizer,pipeline\n",
        "import torch\n",
        "id2label= {\n",
        "    \"0\": \"None\",\n",
        "    \"1\": \"Environmental\",\n",
        "    \"2\": \"Social\",\n",
        "    \"3\": \"Governance\"\n",
        "  }\n",
        "esg_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-esg\", num_labels=4)\n",
        "esg_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-esg\")\n",
        "esg_nlp=pipeline(\"text-classification\",model=esg_model,tokenizer=esg_tokenizer)\n",
        "#print(esg_nlp(\"Reliance continued to face controversies related to allegations of negligence in its health care facilities across the US. In relation to this, it recently faced allegations of sexual assault in its Viirginia facility with lawsuits from former minor patients filed against the company, hospital and former physiotherapist.\"))\n",
        "print(esg_nlp(df['clean_data'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "3924fab4ced34288808d90515d297db7",
            "efd1e7bae3a143cda48d3ba589a245e3",
            "7d030222f47b40cab0c8cc3650811f8c",
            "774203c18c854e49b2df29a54c371af3",
            "4ad57ac458f545b49af012d0af6964d7",
            "6c3382bdd73b4ed79a1c84a06763a2f0",
            "9d5d97aa9e944b22811f09f929471237",
            "6f2da34c10134e5ab293e08a5916210b",
            "85d4c4f8dc5b4e3a8568aeb33fe0ce49",
            "e3c183a066fe4d03ba704bca35856cf9",
            "78bbc674c2e44c1ab4d768f394e718f5"
          ]
        },
        "id": "8_fsM7tV6IzP",
        "outputId": "309c7c5e-3ac3-4feb-b9e5-a9cbde3d7b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3924fab4ced34288808d90515d297db7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'Social', 'score': 0.9554513692855835}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.tagged import NLTKWordTokenizer\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords,wordnet\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer,SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import spacy\n",
        "NER = spacy.load(\"en_core_web_sm\")\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "def is_word_exists(sentence,keyword):\n",
        "  \n",
        "  ps = SnowballStemmer(\"english\")\n",
        "  wn=WordNetLemmatizer()\n",
        "  words=\" \".join([ps.stem(str(i).lower()) for i in word_tokenize(sentence)]) +\" \".join([str(i).lower() for i in word_tokenize(sentence)])+\" \".join([wn.lemmatize(str(i).lower()) for i in word_tokenize(sentence)])\n",
        "  #print(words)\n",
        "  \n",
        "  synonyms=[]\n",
        "  tokens=keyword.split(\" \")\n",
        "  vals=[]\n",
        "  for token in tokens:\n",
        "    flag=False\n",
        "    for syn in wordnet.synsets(token):\n",
        "      for lm in syn.lemmas():\n",
        "              synonyms.append(lm.name())\n",
        "    syn = [token]+synonyms\n",
        "    ps_syn=syn+[ps.stem(w) for w in syn] +[wn.lemmatize(f) for f in syn]\n",
        "    syn=set(ps_syn)\n",
        "    for word in syn:\n",
        "      if word is not None and str(word).lower() in words :\n",
        "        flag=True\n",
        "        break\n",
        "    vals.append(flag)\n",
        "  return len(tokens) == len([f for f in vals if f is True])\n",
        "\n",
        "def get_nature_impact(dict1,message,type):\n",
        "  sentences=sent_tokenize(message)\n",
        "  nature=\"minimal\"\n",
        "  for sentence in sentences:\n",
        "    for key in [\"very serious\",\"serious\",\"medium\"]:\n",
        "\n",
        "      if key ==\"very serious\" and type == \"social\":\n",
        "        item3=dict1[key][\"direct_object\"]\n",
        "        for i3 in item3.split(\",\"):\n",
        "          if is_word_exists(sentence,i3.strip()):\n",
        "            nature=key\n",
        "            return nature\n",
        "      item1=dict1[key][\"object\"]\n",
        "      item2=dict1[key][\"impact\"]\n",
        "      i1_tokens=item1.split(\",\")\n",
        "      i2_tokens=item2.split(\",\")\n",
        "      i1_flag=False\n",
        "      \n",
        "      for i1 in i1_tokens:\n",
        "        i1_flag=is_word_exists(sentence,i1.strip())\n",
        "        if(i1_flag):\n",
        "          break\n",
        "      i2_flag=False\n",
        "      for i2 in i2_tokens:\n",
        "        if any(char.isdigit() for char in i2.strip()):\n",
        "            docs= NER(sentence)\n",
        "            for doc in docs.ents:\n",
        "              if doc.label_ == \"MONEY\":\n",
        "                d=doc.text\n",
        "\n",
        "                tokens=sentence.split(\" \")\n",
        "                k=0\n",
        "                d1=\"\"\n",
        "                while (k<len(tokens)):\n",
        "                  if d in tokens[k]:\n",
        "                    if k<len(tokens)-1:\n",
        "                      d1=str(tokens[k]+tokens[k+1])\n",
        "                    else:\n",
        "                      d1=str(tokens[k])\n",
        "                    break\n",
        "                  k=k+1\n",
        "                if d1.strip() ==\"\":\n",
        "                  continue\n",
        "                num=int(\"\".join([i for i in d1 if i.isdigit() or i==\".\" ]))\n",
        "                if \"million\" in d or \"mn\" in d or \"m\" in d1 :\n",
        "                   num=num*1000000\n",
        "                elif \"billion\" in d or \"bn\" in d or \"b\" in d1:\n",
        "                  num=num*1000000000\n",
        "                d=num\n",
        "\n",
        "                if key == \"very serious\" and d>=1000000000:\n",
        "                  i2_flag=True\n",
        " \n",
        "                elif key == \"serious\" and d>=100000000 and d<1000000000:\n",
        "                  i2_flag=True\n",
        "\n",
        "                elif key == \"medium\" and d<100000000:\n",
        "                  i2_flag=True\n",
        "              if i1_flag and i2_flag:\n",
        "                return key\n",
        "        else:\n",
        "          i2_flag=is_word_exists(sentence,i2.strip())\n",
        "          if i1_flag and i2_flag:\n",
        "            return key\n",
        "      \n",
        "  return nature\n",
        "\n",
        "nature_dict={\"environment\":{\n",
        "              \"very serious\":{\"object\":\"plant, wildlife, habitat, ecosystem\",\"impact\":\"death,dead, destruction,destroy\"},\n",
        "              \"serious\":{\"object\":\"plant, wildlife, habitat, ecosystem\",\"impact\":\"debilitation, injury,'injuri', illness, major damage\"},\n",
        "              \"medium\":{\"object\":\"plant, wildlife, habitat, ecosystem, pollution\",\"impact\":\"damage, short term damage\"},\n",
        "              \"minimal\":{\"object\":\"\",\"impact\":\"\"}},\n",
        "  \"social\":{\n",
        "              \"very serious\":{\"object\":\"human rights, livelihood, life, traditional life, traditional way of life, property\",\"direct_object\":\"death,crimes, dead,disability, permanent disability,torture, rape, enslavement\",\"impact\":\"violation, destruction,serious,destroy\"},\n",
        "              \"serious\":{\"object\":\"property,people,mass,employee,livelihood, life,traditional life, traditional way of life, labor rights, labour rights, civil rights, privacy, collective bargaining\",\"impact\":\"debilitating, damage, impairment, displacement, violation, harm,injuri,injury,illness,risk\"},\n",
        "              \"medium\":{\"object\":\"injury,'injuri', illness, property, livelihood, life, traditional life, traditional way of life\",\"impact\":\"treatable, short-term, short term, temporary, non-serious, light, slight\"},\n",
        "              \"minimal\":{\"object\":\"\",\"impact\":\"\"}},\n",
        "           \n",
        "  \"governance\":{\n",
        "              \"very serious\":{\"object\":\"national government, economy, bribe,unlawfully, loss, company loss, contracts, contracts value, gains, illegal gains, profit, dishonest profit, corrupt gains, tax, income tax\",\"impact\":\"destabilise, substantially destabilised, illegal, dishonest, corrupt, avoided, 1000000000, 10000000000\"},\n",
        "              \"serious\":{\"object\":\"company, non-government customer, unlawfully,private customer, government body, public sector, government organisation, pension funds, pension, bribe, contracts\",\"impact\":\"bankruptcy, 100000000, 5000000000\"},\n",
        "              \"medium\":{\"object\":\"company, B2B, property, government fraud\",\"impact\":\"corruption, fraud, damage, non-serious, slight, light\"},\n",
        "              \"minimal\": {\"object\":\"\",\"impact\":\"\"}}\n",
        "}\n",
        "\"\"\"\n",
        "data1=\"Fire accident happened yesterday night in african forest.1M Animals death and habitat destruction done\"\n",
        "data2=\"People got fired from infosys organization due to dollar to rupee conversion low in india\"\n",
        "data3=\"destabilized happened over year in pakistan and goverment taking minimal actions which effects country economy growth\"\n",
        "print(get_nature_impact(nature_dict[\"environment\"],data1,\"environment\"))\n",
        "print(get_nature_impact(nature_dict[\"social\"],data2,\"social\"))\n",
        "print(get_nature_impact(nature_dict[\"governance\"],data2,\"governance\"))\n",
        "print(get_nature_impact(nature_dict[\"social\"],\"Shell's factory emitted poisonous gases that led to serious health risk to its employees\",\"social\"))\n",
        "print(get_nature_impact(nature_dict[\"social\"],\"Reliance continued to face controversies related to allegations of negligence in its health care facilities across the US. In relation to this, it recently faced allegations of sexual assault in its Viirginia facility with lawsuits from former minor patients filed against the company, hospital and former physiotherapist.\",\"social\"))\n",
        "print(get_nature_impact(nature_dict[\"governance\"],\"The CEO of Shell and his associates were accused of accepting money unlawfully to the tune of $123 mn\",\"governance\"))\n",
        "\"\"\"\n",
        "print(get_nature_impact(nature_dict[\"social\"],df['data'][0],\"social\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWdH891U4afh",
        "outputId": "48d895df-46da-4129-bb55-3ba83e5bd45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "very serious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.tagged import NLTKWordTokenizer\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords,wordnet\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer,SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import spacy\n",
        "NER = spacy.load(\"en_core_web_sm\")\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "def is_word_exists(sentence,keyword):\n",
        "  #print(keyword)\n",
        "  ps = SnowballStemmer(\"english\")\n",
        "  wn=WordNetLemmatizer()\n",
        "  words=\" \".join([ps.stem(str(i).lower()) for i in word_tokenize(sentence)]) +\" \".join([str(i).lower() for i in word_tokenize(sentence)])+\" \".join([wn.lemmatize(str(i).lower()) for i in word_tokenize(sentence)])\n",
        "  #print(words)\n",
        "\n",
        "  synonyms=[]\n",
        "  k1=keyword.split(\" \")\n",
        "  vals=[]\n",
        "  for token in k1:\n",
        "    token=token.strip()\n",
        "    flag=False\n",
        "    for syn in wordnet.synsets(token):\n",
        "      for lm in syn.lemmas():\n",
        "              synonyms.append(lm.name())\n",
        "    syn = [token]+synonyms\n",
        "    ps_syn=syn+[ps.stem(w) for w in syn] +[wn.lemmatize(w) for w in syn]\n",
        "    syn=syn+ps_syn\n",
        "    if \"unlawfully\" in syn :\n",
        "        print(\"word1\") \n",
        "    for word in syn:\n",
        "      \n",
        "      if word is not None and str(word).lower() in words :\n",
        "        flag=True\n",
        "        break\n",
        "    vals.append(flag)\n",
        "  return len(k1) == len([f for f in vals if f is True])\n",
        "\n",
        "def get_scale(dict1,message):\n",
        "  sentences=sent_tokenize(message)\n",
        "  scale=\"minimal\"\n",
        "  for sentence in sentences:\n",
        "    for key in [\"extremely widespread\",\"extensive\",\"limited\"]:\n",
        "      for item in dict1[key]:\n",
        "        item1=item[\"object\"]\n",
        "        item2=item[\"quantity\"]\n",
        "        i1_tokens=item1.strip().split(\",\")\n",
        "        i2_tokens=item2.strip().split(\",\")\n",
        "        i1_flag=False\n",
        "        for i1 in i1_tokens:\n",
        "          i1_flag=is_word_exists(sentence,i1.strip())\n",
        "          if(i1_flag):\n",
        "            break\n",
        "\n",
        "        i2_flag=False\n",
        "        for i2 in i2_tokens:\n",
        "          if any(char.isdigit() for char in i2.strip()):\n",
        "            docs= NER(sentence)\n",
        "            d=\"\"\n",
        "            for doc in docs.ents:\n",
        "              if i2 in [\"economic harm,monetary,economic,financial impact,financial\"]:\n",
        "                if doc.label_ in [\"MONEY\"]:\n",
        "                  d=doc.text\n",
        "              else:\n",
        "                if doc.label_ in [\"CARDINAL\"]:\n",
        "                  d=doc.text\n",
        "            if d.strip() ==\"\":\n",
        "              continue\n",
        "            tokens=sentence.split(\" \")\n",
        "            k=0\n",
        "            d1=\"\"\n",
        "            while (k<len(tokens)):\n",
        "              \n",
        "              if d in tokens[k]:\n",
        "                if \"km2\" in tokens[k+1] :\n",
        "                  d1=tokens[k]\n",
        "                elif k<len(tokens)-1:\n",
        "                  d1=str(tokens[k]+tokens[k+1])\n",
        "                  #print(tokens[k+1])\n",
        "                else:\n",
        "                  d1=str(tokens[k])\n",
        "              break\n",
        "              k=k+1\n",
        "            if d1.strip() ==\"\":\n",
        "              continue\n",
        "              \n",
        "            num=int(\"\".join([i for i in d1 if i.isdigit() ]))\n",
        "            if \"million\" in d1 or \"mn\" in d1 :\n",
        "              num=num*1000000\n",
        "            elif \"billion\" in d1 or \"bn\" in d1:\n",
        "              num=num*1000000000\n",
        "            d=num\n",
        "            if (\">\" in i2.strip() or \">=\" in i2.strip()) and (\"<\" not in i2.strip() or \"between\" not in i2.strip()):\n",
        "              if \">=\" in i2.strip():\n",
        "                if d>=int(\"\".join([i for i in i2.strip() if i.isdigit()])):\n",
        "                  i2_flag=True\n",
        "              else:\n",
        "                if d>int(\"\".join([i for i in i2.strip() if i.isdigit()])):\n",
        "                  i2_flag=True\n",
        "\n",
        "            elif ((\">\" in i2.strip()) and (\"<\" in i2.strip()) or \"between\" in i2.strip()):\n",
        "              if \"between\" in i2.strip():\n",
        "                vals=i2.strip().split(\" \")\n",
        "                low=int(\"\".join([i for i in vals[vals.index(\"between\")+1] if i.isdigit()]))\n",
        "                high=int(\"\".join([i for i in vals[vals.index(\"and\")+1] if i.isdigit()]))\n",
        "                if d>=low and d<=high:\n",
        "                  i2_flag=True\n",
        "            else:\n",
        "              if d< int(\"\".join([i for i in i2.strip() if i.isdigit()])):\n",
        "                i2_flag=True\n",
        "            for key_token in i2.strip().split(\" \"):\n",
        "              if i2_flag and key_token not in [\"between\",\"and\"] and not any(char.isdigit() for char in key_token):\n",
        "                i2_flag=is_word_exists(sentence,key_token)\n",
        "            if i1_flag and i2_flag:\n",
        "              return key\n",
        "          else:\n",
        "            i2_flag=is_word_exists(sentence,i2.strip())\n",
        "            if i1_flag and i2_flag:\n",
        "              return key\n",
        "      \n",
        "  return scale  \n",
        "scale_dict ={\n",
        "  \"environment\":{\n",
        "              \"extremely widespread\":[{\"object\":\"watershed, sea, ocean\",\"quantity\":\">=100 km2, >=100 square kilometre, >=100 square kilometer, >=100 sqkm\"},{\"object\":\"species,wildlife\",\"quantity\":\"global\"},{\"object\":\"barrels, barrels spilled\",\"quantity\":\">=60000\"},{\"object\":\"contributors, company\",\"quantity\":\"=<10, top 10\"},{\"object\":\"duration\",\"quantity\":\">5 years\"},{\"object\":\"sovereign states, countries\",\"quantity\":\"many, several, multiple\"}],\n",
        "              \"extensive\": [{\"object\":\"large bay, river\",\"quantity\":\"between 10 and 99 km2, between 10 and 99 sqkm, between 10 and 99 square kilometre, between 10 and 99 square kilometer\"},{\"object\":\"species, wildlife\",\"quantity\":\"regional, country\"},{\"object\":\"barrels, barrels spilled\",\"quantity\":\"between 5000 and 59999\"},{\"object\":\"contributors, company\",\"quantity\":\"one of many\"}],\n",
        "              \"limited\": [{\"object\":\"water stream, small river, lake, pond\",\"quantity\":\"between 1 and 9 km2, between 1 and 9 sqkm, between 1 and 9 square kilometre, between 1 and 9 square kilometer\"},{\"object\":\"species, wildlife\",\"quantity\":\"local\"},{\"object\":\"barrels, barrels spilled\",\"quantity\":\"between 1500 and 4999\"}],\n",
        "              \"low\":[ {\"object\":\"\",\"quantity\":\"\"}]},\n",
        "   \"social\":{\n",
        "              \"extremely widespread\":[{\"object\":\"people\",\"quantity\":\">=1000\"},{\"object\":\"properties\",\"quantity\":\">=2000\"},{\"object\":\"contributors, company\",\"quantity\":\"<10, top 10\"},{\"object\":\"impact, duration\",\"quantity\":\"long-lasting, >5 years\"},{\"object\":\"economic harm, monetary, economic, financial impact, financial\",\"quantity\":\">=USD 10 bn, >=USD 10 billion\"}],\n",
        "              \"extensive\": [{\"object\":\"people\",\"quantity\":\"between 25 and 999\"},{\"object\":\"properties\",\"quantity\":\"between 100 and 1999\"},{\"object\":\"contributors, company\",\"quantity\":\"one of many\"}],\n",
        "              \"limited\": [{\"object\":\"people\",\"quantity\":\"between 10 and 24\"},{\"object\":\"properties\",\"quantity\":\"between 10 and 99\"}],\n",
        "              \"low\":[ {\"object\":\"\",\"quantity\":\"\"}]},          \n",
        "  \"governance\":{\n",
        "             \"extremely widespread\":[{\"object\":\"people\",\"quantity\":\">1000\"},{\"object\":\"impact\",\"quantity\":\"global\"},{\"object\":\" Argentina, Australia, Brazil, Canada, China, France, Germany, India, Indonesia, Italy, Japan, Korea, Mexico, Russia, Saudi Arabia, South Africa, Turkey, United Kingdom, UK, Britain, England, United States, European Union \",\"quantity\":\"count>3\"},{\"object\":\"impact, duration\",\"quantity\":\"long-lasting, >5 years\"},{\"object\":\"economic harm, monetary, economic, financial impact, financial\",\"quantity\":\">USD 10 bn, >USD 10 billion\"}],\n",
        "              \"extensive\": [{\"object\":\"people\",\"quantity\":\"between 25 and 1000\"}, {\"object\":\" Argentina, Australia, Brazil, Canada, China, France, Germany, India, Indonesia, Italy, Japan, Korea, Mexico, Russia, Saudi Arabia, South Africa, Turkey, United Kingdom, UK, Britain, England, United States, European Union \",\"quantity\":\"count between 1 and 3\"},{\"object\":\"other countries, countries\",\"quantity\":\">=3\"}],\n",
        "              \"limited\": [{\"object\":\"people\",\"quantity\":\"between 10 and 24\"},{\"object\":\"other countries, countries\",\"quantity\":\"between 1 and 2\"},{\"object\":\"minicipalt, local municipalty\",\"quantity\":\" between 1 and 2\"}],\n",
        "              \"low\":[ {\"object\":\"\",\"quantity\":\"\"}]}\n",
        "}\n",
        "#data1=\"Fire accident happened yesterday night in african forest.1M Animals death and habitat destruction done\"\n",
        "#data2=\"People got fired from infosys organization due to dollar to rupee conversion low in india\"\n",
        "#data3=\"destabilized happened over year in pakistan and goverment taking minimal actions which effects country economy growth\"\n",
        "#t=get_scale_impact(scale_dict[\"environment\"],\"small river spread of 9 sqkm\")\n",
        "#print(t)\n",
        "#print(get_social_scale_impact(nature_dict[\"social\"],\"Reliance continued to face controversies related to allegations of negligence in its health care facilities across the US. In relation to this, it recently faced allegations of sexual assault in its Viirginia facility with lawsuits from former minor patients filed against the company, hospital and former physiotherapist.\"))\n",
        "#print(get_governance_scale_impact(nature_dict[\"governance\"],\"The CEO of Shell and his associates were accused of accepting money unlawfully to the tune of $123 mn\"))\n",
        "print(get_scale(scale_dict[\"social\"],df['data'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93184172-4ae5-4938-c680-410188ef7d6f",
        "id": "3Z9oRpCJeD4m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extensive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSTxWfpPoSdZ",
        "outputId": "b5d729d2-3f74-483d-db82-bfa1fbbb02ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "Health & Safety\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification,AutoTokenizer\n",
        "import torch\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    '/content/drive/MyDrive/Model', \n",
        "    num_labels = 26, #number of classifications\n",
        "   output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/Model')\n",
        "model.eval()\n",
        "#text=\"Donard Trump taken actions against climate change but Upper house rejected his plea. \\ still he is pushing withdraw of paris climate change bill\"\n",
        "#text=text.lower()\n",
        "text=\"there were allegations of sexual assault against reliance \"\n",
        "#text=clean_msg\n",
        "inputs = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "prediction = model(\n",
        "            inputs['input_ids'].to(device), \n",
        "            token_type_ids=inputs['token_type_ids'].to(device)\n",
        "        )[0].argmax().item()\n",
        "id2label= {\n",
        "    \"0\": \"Bribery & Fraud\",\n",
        "    \"1\": \"Privacy & Data Security\",\n",
        "    \"2\": \"Human Rights & Community-Other\",\n",
        "    \"3\": \"Governance-Other\",\n",
        "    \"4\": \"AntiCompetitive Practices\",\n",
        "    \"5\": \"Governance-Other\",\n",
        "    \"6\": \"Customer Relations\",\n",
        "    \"7\": \"Governance Structures\",\n",
        "    \"8\": \"Discrimination & Workforce Diversity\",\n",
        "    \"9\": \"Health & Safety\",\n",
        "    \"10\": \"Human Rights & Community\",\n",
        "    \"11\": \"Labor Management Relations\",\n",
        "    \"12\": \"Governance-Other\",\n",
        "    \"13\": \"Energy & Climate Change\",\n",
        "    \"14\": \"Product Safety & Quality\",\n",
        "    \"15\": \"Product Safety & Quality\",\n",
        "    \"16\": \"Marketing & Advertising\",\n",
        "    \"17\": \"Supply Chain Management\",\n",
        "    \"18\": \"Governance-Other\",\n",
        "    \"19\": \"Toxic Emissions & Waste/Operational Waste(Non-Hazardous)\",\n",
        "    \"20\": \"Water Stress\",\n",
        "    \"21\": \"Toxic Emissions & Waste\",\n",
        "    \"22\": \"Privacy & Data Security\",\n",
        "    \"23\": \"Biodiversity & Land Use\",\n",
        "    \"24\": \"Energy & Climate Change\",\n",
        "    \"25\": \"Energy & Climate Change\"\n",
        "  }\n",
        "print(prediction)\n",
        "print(id2label[str(prediction)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract ORG with spacy\n",
        "import spacy\n",
        "import re\n",
        "NER = spacy.load(\"en_core_web_sm\")\n",
        "#raw_text=\"The Indian Space Research Organisation or is the national space agency of India, headquartered in Bengaluru. It operates under Department of Space which is directly overseen by the Prime Minister of India while Chairman of ISRO acts as executive of DOS as well.\"\n",
        "raw_text=df['Title'][27]+\"\\n\"+df[\"News\"][27]\n",
        "text1= NER(raw_text)\n",
        "spacy.explain(\"ORG\")\n",
        "com=[]\n",
        "\n",
        "for word in text1.ents:\n",
        "    if word.label_ in ['ORG']:\n",
        "      com.append(word.text)\n",
        "com=set(com)\n",
        "word_count={}\n",
        "for item in com:\n",
        "  message=raw_text\n",
        "  message=message.replace('(','')\n",
        "  item=item.replace('(','')\n",
        "  count=len(re.findall('(?='+item+')',message))\n",
        "  word_count[item]=count\n",
        "val=0\n",
        "val_key=\"\"\n",
        "for key in word_count.keys():\n",
        "  if val<int(word_count[key]):\n",
        "    val=int(word_count[key])\n",
        "    val_key=key\n",
        "\n",
        "print(val_key)"
      ],
      "metadata": {
        "id": "y0WD6Wv6wV9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e76780-1ffd-463b-d061-5fca8cf51f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SBG Management\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https:// [link text](https:// [link text](https://)))\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "s7c9YMMn0_fk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1M63QiH_DuIurA_boe-fsz8-59IRoSvqN",
      "authorship_tag": "ABX9TyNsBHi7O2bx06KZM1Gv0Y7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3924fab4ced34288808d90515d297db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efd1e7bae3a143cda48d3ba589a245e3",
              "IPY_MODEL_7d030222f47b40cab0c8cc3650811f8c",
              "IPY_MODEL_774203c18c854e49b2df29a54c371af3"
            ],
            "layout": "IPY_MODEL_4ad57ac458f545b49af012d0af6964d7"
          }
        },
        "efd1e7bae3a143cda48d3ba589a245e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3382bdd73b4ed79a1c84a06763a2f0",
            "placeholder": "​",
            "style": "IPY_MODEL_9d5d97aa9e944b22811f09f929471237",
            "value": "Downloading: 100%"
          }
        },
        "7d030222f47b40cab0c8cc3650811f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2da34c10134e5ab293e08a5916210b",
            "max": 226122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85d4c4f8dc5b4e3a8568aeb33fe0ce49",
            "value": 226122
          }
        },
        "774203c18c854e49b2df29a54c371af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c183a066fe4d03ba704bca35856cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_78bbc674c2e44c1ab4d768f394e718f5",
            "value": " 226k/226k [00:00&lt;00:00, 6.40kB/s]"
          }
        },
        "4ad57ac458f545b49af012d0af6964d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3382bdd73b4ed79a1c84a06763a2f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5d97aa9e944b22811f09f929471237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f2da34c10134e5ab293e08a5916210b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d4c4f8dc5b4e3a8568aeb33fe0ce49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3c183a066fe4d03ba704bca35856cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78bbc674c2e44c1ab4d768f394e718f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}